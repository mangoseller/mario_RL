{"eval/std_reward":0,"_runtime":23,"eval/mean_length":4025,"_step":1,"train/mean_reward":0,"eval/min_reward":0,"total_env_steps":200,"train/mean_length":100,"train/num_episodes":2,"_timestamp":1.763181059282012e+09,"global_step":99,"num_updates":1,"eval/max_reward":0,"eval/mean_reward":0,"_wandb":{"runtime":23}}